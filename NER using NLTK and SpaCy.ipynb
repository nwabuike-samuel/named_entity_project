{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resume(object):\n",
    "    def __init__(self, filename=None):\n",
    "        self.filename = filename\n",
    "        \n",
    "    def get(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        fFileObj = open(self.filename, 'rb')\n",
    "        pdfReader = PyPDF2.PdfFileReader(fFileObj)\n",
    "        pageObj = pdfReader.getPage(0)\n",
    "        #print(f\"Number of pages: {reader.getNumPages()}\")\n",
    "        print(\"Total Pages : {} \".format(pdfReader.numPages))\n",
    "        resume = pageObj.extractText()\n",
    "        #resume = nlp(\" \".join(resume.split('\\n')))\n",
    "        print(resume)\n",
    "        return resume\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition using NLTK and SpaCy\n",
    "\n",
    "## Using NLTK\n",
    "1. Word Tokenization\n",
    "2. Sentence Tokenization\n",
    "3. Stopwords\n",
    "4. Part of Speech (POS) Tagging\n",
    "5. Chunking with NLTK\n",
    "6. Chinking with NLTK\n",
    "7. Lemmatization\n",
    "8. Named Entity Recognition - NER\n",
    "\n",
    "## Using SpaCy\n",
    "1. CV review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize\n",
    "### Word Tokenize - returns a set of words in a sentence\n",
    "### Sentence Tokenize - returns chunk of sentence in a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Mr. Smith, how are you doing today?', 'The weather is great, and Python is awesome.', 'The sky is pinkish-blue.', \"You shouldn't eat cardboard.\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "EXAMPLE_TEXT = \"Hello Mr. Smith, how are you doing today? The weather is great, and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard.\"\n",
    "\n",
    "print(sent_tokenize(EXAMPLE_TEXT))\n",
    "\t  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n",
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Stemming \n",
    "#### refers to the process of stripping suffixes from words in attempt to normalize them and reduce them to their non-changing portion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "pythonli\n"
     ]
    }
   ],
   "source": [
    "for w in example_words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = \"It is important to by very pythonly while you are pythoning with python. All pythoners have pythoned poorly at least once.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It\n",
      "is\n",
      "import\n",
      "to\n",
      "by\n",
      "veri\n",
      "pythonli\n",
      "while\n",
      "you\n",
      "are\n",
      "python\n",
      "with\n",
      "python\n",
      ".\n",
      "all\n",
      "python\n",
      "have\n",
      "python\n",
      "poorli\n",
      "at\n",
      "least\n",
      "onc\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(new_text)\n",
    "\n",
    "for w in words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagger: Labels words with their corresponding parts of speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK POS tag list:\n",
    "\n",
    "CC\tcoordinating conjunction\n",
    "\n",
    "CD\tcardinal digit\n",
    "\n",
    "DT\tdeterminer\n",
    "\n",
    "EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "\n",
    "FW\tforeign word\n",
    "\n",
    "IN\tpreposition/subordinating conjunction\n",
    "\n",
    "JJ\tadjective\t'big'\n",
    "\n",
    "JJR\tadjective, comparative\t'bigger'\n",
    "\n",
    "JJS\tadjective, superlative\t'biggest'\n",
    "\n",
    "LS\tlist marker\t1)\n",
    "\n",
    "MD\tmodal\tcould, will\n",
    "\n",
    "NN\tnoun, singular 'desk'\n",
    "\n",
    "NNS\tnoun plural\t'desks'\n",
    "\n",
    "NNP\tproper noun, singular\t'Harrison'\n",
    "\n",
    "NNPS\tproper noun, plural\t'Americans'\n",
    "\n",
    "PDT\tpredeterminer\t'all the kids'\n",
    "\n",
    "POS\tpossessive ending\tparent\\'s\n",
    "\n",
    "PRP\tpersonal pronoun\tI, he, she\n",
    "\n",
    "PRP$\tpossessive pronoun\tmy, his, hers\n",
    "\n",
    "RB\tadverb\tvery, silently,\n",
    "\n",
    "RBR\tadverb, comparative\tbetter\n",
    "\n",
    "RBS\tadverb, superlative\tbest\n",
    "\n",
    "RP\tparticle\tgive up\n",
    "\n",
    "TO\tto\tgo 'to' the store.\n",
    "\n",
    "UH\tinterjection\terrrrrrrrm\n",
    "\n",
    "VB\tverb, base form\ttake\n",
    "\n",
    "VBD\tverb, past tense\ttook\n",
    "\n",
    "VBG\tverb, gerund/present participle\ttaking\n",
    "\n",
    "VBN\tverb, past participle\ttaken\n",
    "\n",
    "VBP\tverb, sing. present, non-3d\ttake\n",
    "\n",
    "VBZ\tverb, 3rd person sing. present\ttakes\n",
    "\n",
    "WDT\twh-determiner\twhich\n",
    "\n",
    "WP\twh-pronoun\twho, what\n",
    "\n",
    "WP$\tpossessive wh-pronoun\twhose\n",
    "\n",
    "WRB\twh-abverb\twhere, when\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PRESIDENT', 'NNP'), ('GEORGE', 'NNP'), ('W.', 'NNP'), ('BUSH', 'NNP'), (\"'S\", 'POS'), ('ADDRESS', 'NNP'), ('BEFORE', 'IN'), ('A', 'NNP'), ('JOINT', 'NNP'), ('SESSION', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('CONGRESS', 'NNP'), ('ON', 'NNP'), ('THE', 'NNP'), ('STATE', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('UNION', 'NNP'), ('January', 'NNP'), ('31', 'CD'), (',', ','), ('2006', 'CD'), ('THE', 'NNP'), ('PRESIDENT', 'NNP'), (':', ':'), ('Thank', 'NNP'), ('you', 'PRP'), ('all', 'DT'), ('.', '.')]\n",
      "[('Mr.', 'NNP'), ('Speaker', 'NNP'), (',', ','), ('Vice', 'NNP'), ('President', 'NNP'), ('Cheney', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('Congress', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Supreme', 'NNP'), ('Court', 'NNP'), ('and', 'CC'), ('diplomatic', 'JJ'), ('corps', 'NN'), (',', ','), ('distinguished', 'JJ'), ('guests', 'NNS'), (',', ','), ('and', 'CC'), ('fellow', 'JJ'), ('citizens', 'NNS'), (':', ':'), ('Today', 'VB'), ('our', 'PRP$'), ('nation', 'NN'), ('lost', 'VBD'), ('a', 'DT'), ('beloved', 'VBN'), (',', ','), ('graceful', 'JJ'), (',', ','), ('courageous', 'JJ'), ('woman', 'NN'), ('who', 'WP'), ('called', 'VBD'), ('America', 'NNP'), ('to', 'TO'), ('its', 'PRP$'), ('founding', 'NN'), ('ideals', 'NNS'), ('and', 'CC'), ('carried', 'VBD'), ('on', 'IN'), ('a', 'DT'), ('noble', 'JJ'), ('dream', 'NN'), ('.', '.')]\n",
      "[('Tonight', 'NN'), ('we', 'PRP'), ('are', 'VBP'), ('comforted', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('hope', 'NN'), ('of', 'IN'), ('a', 'DT'), ('glad', 'JJ'), ('reunion', 'NN'), ('with', 'IN'), ('the', 'DT'), ('husband', 'NN'), ('who', 'WP'), ('was', 'VBD'), ('taken', 'VBN'), ('so', 'RB'), ('long', 'RB'), ('ago', 'RB'), (',', ','), ('and', 'CC'), ('we', 'PRP'), ('are', 'VBP'), ('grateful', 'JJ'), ('for', 'IN'), ('the', 'DT'), ('good', 'JJ'), ('life', 'NN'), ('of', 'IN'), ('Coretta', 'NNP'), ('Scott', 'NNP'), ('King', 'NNP'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('President', 'NNP'), ('George', 'NNP'), ('W.', 'NNP'), ('Bush', 'NNP'), ('reacts', 'VBZ'), ('to', 'TO'), ('applause', 'VB'), ('during', 'IN'), ('his', 'PRP$'), ('State', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('Union', 'NNP'), ('Address', 'NNP'), ('at', 'IN'), ('the', 'DT'), ('Capitol', 'NNP'), (',', ','), ('Tuesday', 'NNP'), (',', ','), ('Jan', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:5]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "process_content()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP)\n",
      "  'S/POS\n",
      "  (Chunk ADDRESS/NNP)\n",
      "  BEFORE/IN\n",
      "  (Chunk A/NNP JOINT/NNP SESSION/NNP)\n",
      "  OF/IN\n",
      "  (Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n",
      "  OF/IN\n",
      "  (Chunk THE/NNP UNION/NNP January/NNP)\n",
      "  31/CD\n",
      "  ,/,\n",
      "  2006/CD\n",
      "  (Chunk THE/NNP PRESIDENT/NNP)\n",
      "  :/:\n",
      "  (Chunk Thank/NNP)\n",
      "  you/PRP\n",
      "  all/DT\n",
      "  ./.)\n",
      "(Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP)\n",
      "(Chunk ADDRESS/NNP)\n",
      "(Chunk A/NNP JOINT/NNP SESSION/NNP)\n",
      "(Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n",
      "(Chunk THE/NNP UNION/NNP January/NNP)\n",
      "(Chunk THE/NNP PRESIDENT/NNP)\n",
      "(Chunk Thank/NNP)\n",
      "(S\n",
      "  (Chunk Mr./NNP Speaker/NNP)\n",
      "  ,/,\n",
      "  (Chunk Vice/NNP President/NNP Cheney/NNP)\n",
      "  ,/,\n",
      "  members/NNS\n",
      "  of/IN\n",
      "  (Chunk Congress/NNP)\n",
      "  ,/,\n",
      "  members/NNS\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (Chunk Supreme/NNP Court/NNP)\n",
      "  and/CC\n",
      "  diplomatic/JJ\n",
      "  corps/NN\n",
      "  ,/,\n",
      "  distinguished/JJ\n",
      "  guests/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  fellow/JJ\n",
      "  citizens/NNS\n",
      "  :/:\n",
      "  Today/VB\n",
      "  our/PRP$\n",
      "  nation/NN\n",
      "  lost/VBD\n",
      "  a/DT\n",
      "  beloved/VBN\n",
      "  ,/,\n",
      "  graceful/JJ\n",
      "  ,/,\n",
      "  courageous/JJ\n",
      "  woman/NN\n",
      "  who/WP\n",
      "  (Chunk called/VBD America/NNP)\n",
      "  to/TO\n",
      "  its/PRP$\n",
      "  founding/NN\n",
      "  ideals/NNS\n",
      "  and/CC\n",
      "  carried/VBD\n",
      "  on/IN\n",
      "  a/DT\n",
      "  noble/JJ\n",
      "  dream/NN\n",
      "  ./.)\n",
      "(Chunk Mr./NNP Speaker/NNP)\n",
      "(Chunk Vice/NNP President/NNP Cheney/NNP)\n",
      "(Chunk Congress/NNP)\n",
      "(Chunk Supreme/NNP Court/NNP)\n",
      "(Chunk called/VBD America/NNP)\n",
      "(S\n",
      "  Tonight/NN\n",
      "  we/PRP\n",
      "  are/VBP\n",
      "  comforted/VBN\n",
      "  by/IN\n",
      "  the/DT\n",
      "  hope/NN\n",
      "  of/IN\n",
      "  a/DT\n",
      "  glad/JJ\n",
      "  reunion/NN\n",
      "  with/IN\n",
      "  the/DT\n",
      "  husband/NN\n",
      "  who/WP\n",
      "  was/VBD\n",
      "  taken/VBN\n",
      "  so/RB\n",
      "  long/RB\n",
      "  ago/RB\n",
      "  ,/,\n",
      "  and/CC\n",
      "  we/PRP\n",
      "  are/VBP\n",
      "  grateful/JJ\n",
      "  for/IN\n",
      "  the/DT\n",
      "  good/JJ\n",
      "  life/NN\n",
      "  of/IN\n",
      "  (Chunk Coretta/NNP Scott/NNP King/NNP)\n",
      "  ./.)\n",
      "(Chunk Coretta/NNP Scott/NNP King/NNP)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(Chunk Applause/NNP)\n",
      "(S\n",
      "  (Chunk President/NNP George/NNP W./NNP Bush/NNP)\n",
      "  reacts/VBZ\n",
      "  to/TO\n",
      "  applause/VB\n",
      "  during/IN\n",
      "  his/PRP$\n",
      "  (Chunk State/NNP)\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (Chunk Union/NNP Address/NNP)\n",
      "  at/IN\n",
      "  the/DT\n",
      "  (Chunk Capitol/NNP)\n",
      "  ,/,\n",
      "  (Chunk Tuesday/NNP)\n",
      "  ,/,\n",
      "  (Chunk Jan/NNP)\n",
      "  ./.)\n",
      "(Chunk President/NNP George/NNP W./NNP Bush/NNP)\n",
      "(Chunk State/NNP)\n",
      "(Chunk Union/NNP Address/NNP)\n",
      "(Chunk Capitol/NNP)\n",
      "(Chunk Tuesday/NNP)\n",
      "(Chunk Jan/NNP)\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:5]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            \n",
    "            print(chunked)\n",
    "            for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
    "                print(subtree)\n",
    "\n",
    "            chunked.draw()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "process_content()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:2]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "\n",
    "            chunkGram = r\"\"\"Chunk: {<.*>+}\n",
    "                                    }<VB.?|IN|DT|TO>+{\"\"\"\n",
    "\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "\n",
    "            chunked.draw()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "process_content()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizer\n",
    "#### lemmatizer is stemming but it takes the context of the word into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "cactus\n",
      "goose\n",
      "rock\n",
      "python\n",
      "good\n",
      "best\n",
      "run\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(lemmatizer.lemmatize(\"cats\"))\n",
    "print(lemmatizer.lemmatize(\"cacti\"))\n",
    "print(lemmatizer.lemmatize(\"geese\"))\n",
    "print(lemmatizer.lemmatize(\"rocks\"))\n",
    "print(lemmatizer.lemmatize(\"python\"))\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"best\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"run\"))\n",
    "print(lemmatizer.lemmatize(\"run\",'v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:3]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            namedEnt = nltk.ne_chunk(tagged, binary=False)\n",
    "            namedEnt.draw()\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import random\n",
    "#!pip install PyPDF2\n",
    "import PyPDF2\n",
    "import requests\n",
    "import json\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John - PERSON\n",
      "New York - GPE\n",
      "Abhishek - PERSON\n",
      "11PM - CARDINAL\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp('John lives in New York, where is Mr.Abhishek its already 11PM, he likes burger so he went to KFC')\n",
    "for i in doc1.ents:\n",
    "  print(i.text,'-',i.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John John PROPN NNP nsubj Xxxx True False\n",
      "lives live VERB VBZ ccomp xxxx True False\n",
      "in in ADP IN prep xx True True\n",
      "New New PROPN NNP compound Xxx True False\n",
      "York York PROPN NNP pobj Xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "where where SCONJ WRB advmod xxxx True True\n",
      "is be AUX VBZ relcl xx True True\n",
      "Mr. Mr. PROPN NNP compound Xx. False False\n",
      "Abhishek Abhishek PROPN NNP nsubj Xxxxx True False\n",
      "its its PRON PRP$ poss xxx True True\n",
      "already already ADV RB advmod xxxx True True\n",
      "11PM 11pm NUM CD appos ddXX False False\n",
      ", , PUNCT , punct , False False\n",
      "he he PRON PRP nsubj xx True True\n",
      "likes like VERB VBZ ROOT xxxx True False\n",
      "burger burger NOUN NN dobj xxxx True False\n",
      "so so SCONJ IN mark xx True True\n",
      "he he PRON PRP nsubj xx True True\n",
      "went go VERB VBD advcl xxxx True False\n",
      "to to ADP IN prep xx True True\n",
      "KFC KFC PROPN NNP pobj XXX True False\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "     print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Countries, cities, states'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"GPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    John\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " lives in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    New York\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", where is Mr.\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Abhishek\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " its already \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    11PM\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ", he likes burger so he went to KFC</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc1, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"b03e375867e248d18e4e4aedb07db73b-0\" class=\"displacy\" width=\"2450\" height=\"437.0\" direction=\"ltr\" style=\"max-width: none; height: 437.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">John</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">lives</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">New</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">York,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">where</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">Mr.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">Abhishek</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">its</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">already</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">11PM,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1490\">he</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1490\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1610\">likes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1610\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1730\">burger</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1730\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\">so</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1970\">he</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1970\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2090\">went</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2090\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2210\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2210\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2330\">KFC</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2330\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-0\" stroke-width=\"2px\" d=\"M70,302.0 C70,242.0 150.0,242.0 150.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,304.0 L62,292.0 78,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-1\" stroke-width=\"2px\" d=\"M190,302.0 C190,2.0 1610.0,2.0 1610.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M190,304.0 L182,292.0 198,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-2\" stroke-width=\"2px\" d=\"M190,302.0 C190,242.0 270.0,242.0 270.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270.0,304.0 L278.0,292.0 262.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-3\" stroke-width=\"2px\" d=\"M430,302.0 C430,242.0 510.0,242.0 510.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,304.0 L422,292.0 438,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-4\" stroke-width=\"2px\" d=\"M310,302.0 C310,182.0 515.0,182.0 515.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M515.0,304.0 L523.0,292.0 507.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-5\" stroke-width=\"2px\" d=\"M670,302.0 C670,242.0 750.0,242.0 750.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670,304.0 L662,292.0 678,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-6\" stroke-width=\"2px\" d=\"M550,302.0 C550,182.0 755.0,182.0 755.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M755.0,304.0 L763.0,292.0 747.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-7\" stroke-width=\"2px\" d=\"M910,302.0 C910,242.0 990.0,242.0 990.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910,304.0 L902,292.0 918,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-8\" stroke-width=\"2px\" d=\"M790,302.0 C790,182.0 995.0,182.0 995.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M995.0,304.0 L1003.0,292.0 987.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-9\" stroke-width=\"2px\" d=\"M1150,302.0 C1150,182.0 1355.0,182.0 1355.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1150,304.0 L1142,292.0 1158,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-10\" stroke-width=\"2px\" d=\"M1270,302.0 C1270,242.0 1350.0,242.0 1350.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270,304.0 L1262,292.0 1278,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-11\" stroke-width=\"2px\" d=\"M1030,302.0 C1030,122.0 1360.0,122.0 1360.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1360.0,304.0 L1368.0,292.0 1352.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-12\" stroke-width=\"2px\" d=\"M1510,302.0 C1510,242.0 1590.0,242.0 1590.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1510,304.0 L1502,292.0 1518,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-13\" stroke-width=\"2px\" d=\"M1630,302.0 C1630,242.0 1710.0,242.0 1710.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1710.0,304.0 L1718.0,292.0 1702.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-14\" stroke-width=\"2px\" d=\"M1870,302.0 C1870,182.0 2075.0,182.0 2075.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1870,304.0 L1862,292.0 1878,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-15\" stroke-width=\"2px\" d=\"M1990,302.0 C1990,242.0 2070.0,242.0 2070.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1990,304.0 L1982,292.0 1998,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-16\" stroke-width=\"2px\" d=\"M1630,302.0 C1630,62.0 2085.0,62.0 2085.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2085.0,304.0 L2093.0,292.0 2077.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-17\" stroke-width=\"2px\" d=\"M2110,302.0 C2110,242.0 2190.0,242.0 2190.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2190.0,304.0 L2198.0,292.0 2182.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b03e375867e248d18e4e4aedb07db73b-0-18\" stroke-width=\"2px\" d=\"M2230,302.0 C2230,242.0 2310.0,242.0 2310.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b03e375867e248d18e4e4aedb07db73b-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2310.0,304.0 L2318.0,292.0 2302.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(str(doc1[0:])), style='dep', jupyter = True, options = {'distance': 120})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
